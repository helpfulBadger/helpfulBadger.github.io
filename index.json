[{
    "title": "Putting It All Together with Composite Authorization",
    "date": "September 7, 2020",
    "description": "Learn how to Implement Application Specific Authorization Rules",
    "body": "Photo by Thom Bradley on Unsplash\nGetting Started with Envoy \u0026amp; Open Policy Agent \u0026mdash; 07 \u0026mdash; Learn how to Implement Application Specific Authorization Rules This is the 7th Envoy \u0026amp; Open Policy Agent Getting Started Guide. Each guide is intended to explore a single feature and walk through a simple implementation. Each guide builds on the concepts explored in the previous guide with the end goal of building a very powerful authorization service by the end of the series.\nThe source code for this getting started example is located on Github. \u0026mdash;\u0026mdash;\u0026gt; Envoy \u0026amp; OPA GS # 7 \nHere is a list of the Getting Started Guides that are currently available.\nGetting Started Guides  Using Envoy as a Front Proxy Adding Observability Tools Plugging Open Policy Agent into Envoy Using the Open Policy Agent CLI JWS Signature Validation with OPA JWS Signature Validation with Envoy Putting It All Together with Composite Authorization  Draft Article that is Under construction Introduction In this example we are going to simulate an ecommerce company called Example.com that has a published set of APIs and multiple client applications. Each client application has:\n Different access rights to each published API Different operations they are allowed to perform on the APIs that it has access to Different types of users that are allowed to use the application  There are a lot of other rules that we will eventually be interested in implementing. However, this set of rules is complex enough to demonstrate how we can put together what we have learned so far into a little authorization system.\nExample.com\u0026rsquo;s APIs Here are Example.com\u0026rsquo;s published APIs.\n /api/customer/* /api/customer/*/account/* /api/customer/*/messages/* /api/customer/*/order/* /api/customer/*/paymentcard/* /api/featureFlags /api/order/* /api/order/*/payment/* /api/product/* /api/shipment/*   The customer API, /api/customer/*, allows users manage customer profiles in our customer system of record. The accounts API, /api/customer/*/account/*, allows users to manage accounts for a specific customer in the system of record for accounts. The messages API, /api/customer/*/messages/*, allows users to send and receive messages related to a specific customer in the messaging system. The customer\u0026rsquo;s order API, /api/customer/*/order/*, allows users to manage a customer\u0026rsquo;s orders. The customer\u0026rsquo;s payment card API, /api/customer/*/paymentcard/*, allows users to manage a customer\u0026rsquo;s debit or credit cards. The feature flag API, /api/featureFlags, allows an application to retrieve the feature flags for the app e.g. which features are turned on or off and any customer specific features that are available or not. The order API, /api/order/*, allows users to get, create, update or delete orders for any customer. The order payments API, /api/order/*/payment/*, allows users to manage payments for any order. No shopping cart API is provided. An order in draft status is the equivalent of a shopping cart. The product API, /api/product/*, allows users to manage the products that are available for purchase. The shipment API, /api/shipment/*, allows users to manage shipment for an order.  API Endpoint Definition As the basis for our security policies we need a data structure that contains all of possible actions that a user and client application can take. For this example, we define a URI pattern and a method being attempted on that URI as an endpoint. The id field uniquely identifies each endpoint and will be used in the process of actually specifying what endpoints an application has access to.\n [ {\"id\":\"001\",\"method\":\"GET\", \"pattern\":\"/api/customer\"}, {\"id\":\"002\",\"method\":\"POST\", \"pattern\":\"/api/customer\"}, {\"id\":\"003\",\"method\":\"DELETE\",\"pattern\":\"/api/customer/*\"}, {\"id\":\"004\",\"method\":\"GET\", \"pattern\":\"/api/customer/*\"}, {\"id\":\"005\",\"method\":\"POST\", \"pattern\":\"/api/customer/*\"}, {\"id\":\"006\",\"method\":\"PUT\", \"pattern\":\"/api/customer/*\"}, {\"id\":\"007\",\"method\":\"GET\", \"pattern\":\"/api/customer/*/account\"}, {\"id\":\"008\",\"method\":\"POST\", \"pattern\":\"/api/customer/*/account\"}, ... ]  Client Application API Contracts The next piece of data that we need to build our example authorization solution is a mapping between each client application and the endponts that it is allowed to access. The data structure below holds that information. The unique ID for each application is a key in this data structure and the value is an array of all of the endpoint IDs that the application has access to.\n apiPermissions = { \"app_123456\": [  \"001\",\"004\",\"007\",\"010\",\"012\",\"015\",\"018\",\"021\",\"024\",\"027\",\"031\",\"034\",\"037\",\"040\",\"043\",\"046\",\"049\",\"052\",\"055\"  ], \"app_000123\":[  \"001\", \"002\", \"003\", \"004\", \"005\", \"006\", \"007\", \"008\", \"009\", \"010\", \"011\", \"012\", \"013\", \"014\", \"015\", \"016\", \"017\", \"018\", \"019\", \"020\", \"021\", \"022\", \"023\", \"024\", \"025\", \"026\", \"027\", \"028\", \"029\", \"030\", \"031\", \"032\", \"033\", \"034\", \"035\", \"036\", \"037\", \"038\", \"039\", \"040\", \"041\", \"042\", \"043\", \"044\", \"045\", \"046\", \"047\", \"048\", \"049\", \"050\", \"051\", \"052\", \"053\", \"054\", \"055\", \"056\", \"057\"  ] }  Authorized End User Identity Providers / JWS Issuers for each Client Application Just for fun and simplicity we want to make sure that a hacker has not found a way to use or simulate using an application that is intended for another type of user. So, the data structure below lists the identity providers that are permitted for each application. So, the data structure below means that app_123456 is only allowed to be used by external customers. app_000123 is intended only for use by employees and contractors of example.com (i.e. the workforce). This is a more powerful application that can take action on behalf of the company and on behalf of any of the company\u0026rsquo;s customer. This is very coarse grained security. In a real application we would also put in a lot of user specific rights and access controls. In a later getting started guide we will show how we can start to layer OPA Policies, getting volatile data from external sources and other techniques to implement more realistic security policies.\n idProviderPermissions = { \"app_123456\":[\"customerIdentity.example.com\"], \"app_000123\":[\"workforceIdentity.example.com\"] }  ",
    "ref": "/blog/envoy_opa_7_app_contracts/"
  },{
    "title": "JWS Signature Validation with Envoy",
    "date": "September 7, 2020",
    "description": "Learn how to validate JWS signatures natively with Envoy",
    "body": "Photo by Cytonn Photography on Unsplash\nGetting Started with Envoy \u0026amp; Open Policy Agent \u0026mdash; 06 \u0026mdash; JWS Signature Validation with Envoy This is the 6th Envoy \u0026amp; Open Policy Agent Getting Started Guide. Each guide is intended to explore a single feature and walk through a simple implementation. Each guide builds on the concepts explored in the previous guide with the end goal of building a very powerful authorization service by the end of the series.\nThe source code for this getting started example is located on Github. \u0026mdash;\u0026mdash;\u0026gt; Envoy \u0026amp; OPA GS # 6 \nHere is a list of the Getting Started Guides that are currently available.\nGetting Started Guides  Using Envoy as a Front Proxy Adding Observability Tools Plugging Open Policy Agent into Envoy Using the Open Policy Agent CLI JWS Signature Validation with OPA JWS Signature Validation with Envoy Putting It All Together with Composite Authorization  Introduction One of the HTTP filters available is the JSON Web Token filter. It is color coded in red below. You an specify any number of providers. For each provider the developer specifies the desired validation rules. In our case we have 3 tokens that we will be validating. For each we specify:\n The issuers and audiences that must be present. Just like with Open Policy Agent audiences, the requirement is that the specified audience is matches one of the audiences in the array. The from_headers property tells Envoy where to find the JWS The forward property specifies if the token should be forwarded to the protected API or if the header should be removed before forwarding. If the JWS tokens can be misused by the protected API then they should be removed. The local_jwks propery allows you to specify the JSON web keyset in the configuration. Another option is to retrieve them from an HTTP endpoint that hosts the key set.  The configuration below shows the properties we just described in the color red.\n static_resources: listeners: - address: socket_address: address: 0.0.0.0 port_value: 80 filter_chains: - filters: - name: envoy.filters.network.http_connection_manager typed_config: \"@type\": type.googleapis.com/envoy.extensions.filters.network.http_connection_manager.v3.HttpConnectionManager codec_type: auto stat_prefix: ingress_http route_config: name: local_route virtual_hosts: - name: backend domains: [\"*\"] routes: - match: { prefix: \"/\" } route: { cluster: service } http_filters: - name: envoy.filters.http.jwt_authn typed_config: \"@type\": \"type.googleapis.com/envoy.extensions.filters.http.jwt_authn.v3.JwtAuthentication\" providers: workforce_provider: issuer: workforceIdentity.example.com audiences: - apigateway.example.com from_headers: - name: \"actor-token\" value_prefix: \"\" forward: true local_jwks: inline_string: \"{\\\"keys\\\":[{\\\"use\\\":\\\"sig\\\",\\\"kty\\\":\\\"EC\\\",\\\"kid\\\":\\\"APIGW-ES256\\\",\\\"crv\\\":\\\"P-256\\\",\\\"alg\\\":\\\"ES256\\\",\\\"x\\\":\\\"g3uF5OZrWsU6yKJhv0FQxhALlmNbw6_Wa9_exT3-eNA\\\",\\\"y\\\":\\\"lJbCP1oz0vDs6Dxd_3my5Ga5fLSXRDzQVbTTlt9pr98\\\"},{\\\"use\\\":\\\"sig\\\",\\\"kty\\\":\\\"EC\\\",\\\"kid\\\":\\\"custIDP-ES256\\\",\\\"crv\\\":\\\"P-256\\\",\\\"alg\\\":\\\"ES256\\\",\\\"x\\\":\\\"HmVjNgoTIECfvja3E7WZX2H1OzXtvDhD5_SSMXGYxZU\\\",\\\"y\\\":\\\"ugCW-AoKaSyNqIbyNUgRWMJ8WY6s2W78YI2LdVVTGcY\\\"},{\\\"use\\\":\\\"sig\\\",\\\"kty\\\":\\\"EC\\\",\\\"kid\\\":\\\"workforceIDP-ES256\\\",\\\"crv\\\":\\\"P-256\\\",\\\"alg\\\":\\\"ES256\\\",\\\"x\\\":\\\"_Vg3wsKsY9XH5E5aPn2SLUTUljgum2TXnDY7m73p2Ek\\\",\\\"y\\\":\\\"rSbvTXUdPnFpJq5zqgRLMMAQP8bJ7UcggP1ERkEibGI\\\"},{\\\"use\\\":\\\"sig\\\",\\\"kty\\\":\\\"RSA\\\",\\\"kid\\\":\\\"APIGW-RS256\\\",\\\"alg\\\":\\\"RS256\\\",\\\"n\\\":\\\"thiAsWa8crD-RhGbAewoYjyWpgZpaFKHWqzqAM2iCJ94eQnSwFJJcFayOklSfKK8tUUYulG7FQijpdBLVzbilPtpYK8HjHoLZBLrvNPbEvwlMCVMDX5ttyn1lJV-6momFwuV6EJFnPMXJQU3KTX_QeFejiamxmYQsakyWxxDtTWJ1XAlvtIX3k0osQbFrLbF5SGIwAk9UBFlm2B_3M0lbqu6w8eOxgSc3z-Owd6maYu2Q43MZv-opjObHNfcc60o90iOO9pY5_qSkJt7Slf2cuKU6eOUjsoSCOgValKngogup_itt7LJkrt-ugFiwUITEt6V6MY1MHEw1RgM75N_iQ\\\",\\\"e\\\":\\\"AQAB\\\"},{\\\"use\\\":\\\"sig\\\",\\\"kty\\\":\\\"RSA\\\",\\\"kid\\\":\\\"custIDP-RS256\\\",\\\"alg\\\":\\\"RS256\\\",\\\"n\\\":\\\"z6AtZ3MpSZ1dd-AFyfxk5stjIrbLa8GLSq0GPqZ5RciZIkv-ad-phosgPSDvG1Nx4pcZcENrXAdMA6v6FjRvdGT0EH9CU2vXTu5kCmGP1vV1WfzFdL3K-mswnEaT6-9bO4-m6SEmR3J3YV5QwFVvxIVJqFSmLIggl1PVCM0pXCYb6vkcacg24E-vh6J28LdZmQFqmWHrF7mOL59oz1Gx8ePOr4WnqhP991DeIpzgiofGAS7QQSiNQoKvtizITk3-kcpjWmdw0Zh32xmhsUCu4NKn8DjY2dJ2-WwcL3KK__E0WBJt3I97Nr-m88BSEVl3-P--fsRiEgIP1Co2ulGMbQ\\\",\\\"e\\\":\\\"AQAB\\\"},{\\\"use\\\":\\\"sig\\\",\\\"kty\\\":\\\"RSA\\\",\\\"kid\\\":\\\"workforceIDP-RS256\\\",\\\"alg\\\":\\\"RS256\\\",\\\"n\\\":\\\"ucjZ1pagZuXL4GkFXzG7llZbhPUkl1GzG2vyE0YC3NCvgf2WS67KRH6ck_iMHsWraaPdEcbB8t6ftr0qEXC1ciwVc656Q4V4L_-pxWcD1XMfdiZoViaKyMlq1QzB55XgzM1g7cvgg6_rCmTEmTo3-LUvFd7HxpdHdkYz0U_EUmEB8amz3NxR3LaB-STyxnlsRDrIKmYqDNaPqArdn44INwkGeuJUir0ojw5gdbbazT1NIsuJb2y0zHXuu9ESnyKB8N40ydYe2ECxkdynOQaHt8tCKWhh3F32VwOOuZx34RuVSA_bQraGrduVBd05fEdsPUxq38f1-Z7I5YuokqE_Dw\\\",\\\"e\\\":\\\"AQAB\\\"}]}\" consumer_provider: issuer: customerIdentity.example.com audiences: - apigateway.example.com from_headers: - name: \"subject-token\" value_prefix: \"\" forward: true local_jwks: inline_string: \"{\\\"keys\\\":[{\\\"use\\\":\\\"sig\\\",\\\"kty\\\":\\\"EC\\\",\\\"kid\\\":\\\"APIGW-ES256\\\",\\\"crv\\\":\\\"P-256\\\",\\\"alg\\\":\\\"ES256\\\",\\\"x\\\":\\\"g3uF5OZrWsU6yKJhv0FQxhALlmNbw6_Wa9_exT3-eNA\\\",\\\"y\\\":\\\"lJbCP1oz0vDs6Dxd_3my5Ga5fLSXRDzQVbTTlt9pr98\\\"},{\\\"use\\\":\\\"sig\\\",\\\"kty\\\":\\\"EC\\\",\\\"kid\\\":\\\"custIDP-ES256\\\",\\\"crv\\\":\\\"P-256\\\",\\\"alg\\\":\\\"ES256\\\",\\\"x\\\":\\\"HmVjNgoTIECfvja3E7WZX2H1OzXtvDhD5_SSMXGYxZU\\\",\\\"y\\\":\\\"ugCW-AoKaSyNqIbyNUgRWMJ8WY6s2W78YI2LdVVTGcY\\\"},{\\\"use\\\":\\\"sig\\\",\\\"kty\\\":\\\"EC\\\",\\\"kid\\\":\\\"workforceIDP-ES256\\\",\\\"crv\\\":\\\"P-256\\\",\\\"alg\\\":\\\"ES256\\\",\\\"x\\\":\\\"_Vg3wsKsY9XH5E5aPn2SLUTUljgum2TXnDY7m73p2Ek\\\",\\\"y\\\":\\\"rSbvTXUdPnFpJq5zqgRLMMAQP8bJ7UcggP1ERkEibGI\\\"},{\\\"use\\\":\\\"sig\\\",\\\"kty\\\":\\\"RSA\\\",\\\"kid\\\":\\\"APIGW-RS256\\\",\\\"alg\\\":\\\"RS256\\\",\\\"n\\\":\\\"thiAsWa8crD-RhGbAewoYjyWpgZpaFKHWqzqAM2iCJ94eQnSwFJJcFayOklSfKK8tUUYulG7FQijpdBLVzbilPtpYK8HjHoLZBLrvNPbEvwlMCVMDX5ttyn1lJV-6momFwuV6EJFnPMXJQU3KTX_QeFejiamxmYQsakyWxxDtTWJ1XAlvtIX3k0osQbFrLbF5SGIwAk9UBFlm2B_3M0lbqu6w8eOxgSc3z-Owd6maYu2Q43MZv-opjObHNfcc60o90iOO9pY5_qSkJt7Slf2cuKU6eOUjsoSCOgValKngogup_itt7LJkrt-ugFiwUITEt6V6MY1MHEw1RgM75N_iQ\\\",\\\"e\\\":\\\"AQAB\\\"},{\\\"use\\\":\\\"sig\\\",\\\"kty\\\":\\\"RSA\\\",\\\"kid\\\":\\\"custIDP-RS256\\\",\\\"alg\\\":\\\"RS256\\\",\\\"n\\\":\\\"z6AtZ3MpSZ1dd-AFyfxk5stjIrbLa8GLSq0GPqZ5RciZIkv-ad-phosgPSDvG1Nx4pcZcENrXAdMA6v6FjRvdGT0EH9CU2vXTu5kCmGP1vV1WfzFdL3K-mswnEaT6-9bO4-m6SEmR3J3YV5QwFVvxIVJqFSmLIggl1PVCM0pXCYb6vkcacg24E-vh6J28LdZmQFqmWHrF7mOL59oz1Gx8ePOr4WnqhP991DeIpzgiofGAS7QQSiNQoKvtizITk3-kcpjWmdw0Zh32xmhsUCu4NKn8DjY2dJ2-WwcL3KK__E0WBJt3I97Nr-m88BSEVl3-P--fsRiEgIP1Co2ulGMbQ\\\",\\\"e\\\":\\\"AQAB\\\"},{\\\"use\\\":\\\"sig\\\",\\\"kty\\\":\\\"RSA\\\",\\\"kid\\\":\\\"workforceIDP-RS256\\\",\\\"alg\\\":\\\"RS256\\\",\\\"n\\\":\\\"ucjZ1pagZuXL4GkFXzG7llZbhPUkl1GzG2vyE0YC3NCvgf2WS67KRH6ck_iMHsWraaPdEcbB8t6ftr0qEXC1ciwVc656Q4V4L_-pxWcD1XMfdiZoViaKyMlq1QzB55XgzM1g7cvgg6_rCmTEmTo3-LUvFd7HxpdHdkYz0U_EUmEB8amz3NxR3LaB-STyxnlsRDrIKmYqDNaPqArdn44INwkGeuJUir0ojw5gdbbazT1NIsuJb2y0zHXuu9ESnyKB8N40ydYe2ECxkdynOQaHt8tCKWhh3F32VwOOuZx34RuVSA_bQraGrduVBd05fEdsPUxq38f1-Z7I5YuokqE_Dw\\\",\\\"e\\\":\\\"AQAB\\\"}]}\" gateway_provider: issuer: apigateway.example.com audiences: - apigateway.example.com from_headers: - name: \"app-token\" value_prefix: \"\" forward: true local_jwks: inline_string: \"{\\\"keys\\\":[{\\\"use\\\":\\\"sig\\\",\\\"kty\\\":\\\"EC\\\",\\\"kid\\\":\\\"APIGW-ES256\\\",\\\"crv\\\":\\\"P-256\\\",\\\"alg\\\":\\\"ES256\\\",\\\"x\\\":\\\"g3uF5OZrWsU6yKJhv0FQxhALlmNbw6_Wa9_exT3-eNA\\\",\\\"y\\\":\\\"lJbCP1oz0vDs6Dxd_3my5Ga5fLSXRDzQVbTTlt9pr98\\\"},{\\\"use\\\":\\\"sig\\\",\\\"kty\\\":\\\"EC\\\",\\\"kid\\\":\\\"custIDP-ES256\\\",\\\"crv\\\":\\\"P-256\\\",\\\"alg\\\":\\\"ES256\\\",\\\"x\\\":\\\"HmVjNgoTIECfvja3E7WZX2H1OzXtvDhD5_SSMXGYxZU\\\",\\\"y\\\":\\\"ugCW-AoKaSyNqIbyNUgRWMJ8WY6s2W78YI2LdVVTGcY\\\"},{\\\"use\\\":\\\"sig\\\",\\\"kty\\\":\\\"EC\\\",\\\"kid\\\":\\\"workforceIDP-ES256\\\",\\\"crv\\\":\\\"P-256\\\",\\\"alg\\\":\\\"ES256\\\",\\\"x\\\":\\\"_Vg3wsKsY9XH5E5aPn2SLUTUljgum2TXnDY7m73p2Ek\\\",\\\"y\\\":\\\"rSbvTXUdPnFpJq5zqgRLMMAQP8bJ7UcggP1ERkEibGI\\\"},{\\\"use\\\":\\\"sig\\\",\\\"kty\\\":\\\"RSA\\\",\\\"kid\\\":\\\"APIGW-RS256\\\",\\\"alg\\\":\\\"RS256\\\",\\\"n\\\":\\\"thiAsWa8crD-RhGbAewoYjyWpgZpaFKHWqzqAM2iCJ94eQnSwFJJcFayOklSfKK8tUUYulG7FQijpdBLVzbilPtpYK8HjHoLZBLrvNPbEvwlMCVMDX5ttyn1lJV-6momFwuV6EJFnPMXJQU3KTX_QeFejiamxmYQsakyWxxDtTWJ1XAlvtIX3k0osQbFrLbF5SGIwAk9UBFlm2B_3M0lbqu6w8eOxgSc3z-Owd6maYu2Q43MZv-opjObHNfcc60o90iOO9pY5_qSkJt7Slf2cuKU6eOUjsoSCOgValKngogup_itt7LJkrt-ugFiwUITEt6V6MY1MHEw1RgM75N_iQ\\\",\\\"e\\\":\\\"AQAB\\\"},{\\\"use\\\":\\\"sig\\\",\\\"kty\\\":\\\"RSA\\\",\\\"kid\\\":\\\"custIDP-RS256\\\",\\\"alg\\\":\\\"RS256\\\",\\\"n\\\":\\\"z6AtZ3MpSZ1dd-AFyfxk5stjIrbLa8GLSq0GPqZ5RciZIkv-ad-phosgPSDvG1Nx4pcZcENrXAdMA6v6FjRvdGT0EH9CU2vXTu5kCmGP1vV1WfzFdL3K-mswnEaT6-9bO4-m6SEmR3J3YV5QwFVvxIVJqFSmLIggl1PVCM0pXCYb6vkcacg24E-vh6J28LdZmQFqmWHrF7mOL59oz1Gx8ePOr4WnqhP991DeIpzgiofGAS7QQSiNQoKvtizITk3-kcpjWmdw0Zh32xmhsUCu4NKn8DjY2dJ2-WwcL3KK__E0WBJt3I97Nr-m88BSEVl3-P--fsRiEgIP1Co2ulGMbQ\\\",\\\"e\\\":\\\"AQAB\\\"},{\\\"use\\\":\\\"sig\\\",\\\"kty\\\":\\\"RSA\\\",\\\"kid\\\":\\\"workforceIDP-RS256\\\",\\\"alg\\\":\\\"RS256\\\",\\\"n\\\":\\\"ucjZ1pagZuXL4GkFXzG7llZbhPUkl1GzG2vyE0YC3NCvgf2WS67KRH6ck_iMHsWraaPdEcbB8t6ftr0qEXC1ciwVc656Q4V4L_-pxWcD1XMfdiZoViaKyMlq1QzB55XgzM1g7cvgg6_rCmTEmTo3-LUvFd7HxpdHdkYz0U_EUmEB8amz3NxR3LaB-STyxnlsRDrIKmYqDNaPqArdn44INwkGeuJUir0ojw5gdbbazT1NIsuJb2y0zHXuu9ESnyKB8N40ydYe2ECxkdynOQaHt8tCKWhh3F32VwOOuZx34RuVSA_bQraGrduVBd05fEdsPUxq38f1-Z7I5YuokqE_Dw\\\",\\\"e\\\":\\\"AQAB\\\"}]}\" rules: - match: prefix: / requires: requires_all: requirements: - provider_name: workforce_provider - provider_name: consumer_provider - provider_name: gateway_provider - name: envoy.filters.http.router typed_config: {} clusters: - name: service connect_timeout: 0.25s type: STRICT_DNS lb_policy: round_robin load_assignment: cluster_name: service endpoints: - lb_endpoints: - endpoint: address: socket_address: address: ${SERVICE_NAME} port_value: ${SERVICE_PORT} admin: access_log_path: \"/dev/null\" address: socket_address: address: 0.0.0.0 port_value: 8001  The section in orange above is the rules section. It defines under what conditions to look for and validate a JWS. The match section defines what prefixes to look for. The slash will look for JWS tokens on every URI path. We can specify quite a few rules to determine how many and which tokens we require and under what circumstances. The Official JWT Auth documentation specifies several other options on how to craft logic using and, or and any operations as well as other locations where JWS tokens can be located. There isn\u0026rsquo;t as much control over what response to return to clients in the case of a failed authentication. OPA lets the developer change chose the HTTP Status code, include messages in the response body add headers etc. Envoy\u0026rsquo;s built in feature simply returns an HTTP 401 Unauthorized response.\nTo see this capability in action, simply run the demonstrate_envoy_jws_validation.sh script. The output is similar to the completed solution from the previous lesson. The script also dumps the Envoy logs to show the information that you have available to trouble shoot issues. Below is a screen shot of the log statements that show Envoy extracting the tokens, performing the validation and logging the result.\nConclusion In this getting started example, we successfully validated 3 different JWS tokens in a single request and had flexibility to chose where the tokens were pulled from, how many tokens were required and under what conditions those tokens were needed. In our next getting started guide, we will use Open Policy Agent and our identity tokens to make some more sophisticated authorization decisions.\n",
    "ref": "/blog/envoy_opa_6_envoy_jws/"
  },{
    "title": "JWS Signature Validation with OPA",
    "date": "September 7, 2020",
    "description": "Learn how to validate JWS signatures with Open Policy Agent",
    "body": "Photo by SkillScouter on Unsplash\nGetting Started with Envoy \u0026amp; Open Policy Agent \u0026mdash; 05 \u0026mdash; JWS Signature Validation with OPA This is the 5th Envoy \u0026amp; Open Policy Agent Getting Started Guide. Each guide is intended to explore a single feature and walk through a simple implementation. Each guide builds on the concepts explored in the previous guide with the end goal of building a very powerful authorization service by the end of the series.\nThe source code for this getting started example is located on Github. \u0026mdash;\u0026mdash;\u0026gt; Envoy \u0026amp; OPA GS # 5 \nHere is a list of the Getting Started Guides that are currently available.\nGetting Started Guides  Using Envoy as a Front Proxy Adding Observability Tools Plugging Open Policy Agent into Envoy Using the Open Policy Agent CLI JWS Signature Validation with OPA JWS Signature Validation with Envoy Putting It All Together with Composite Authorization  Introduction This getting started guide will validate 3 different identity tokens that are expressed as Signed JSON web tokens (JWS) for short. This guide assumes knowledge of several IETF RFCs:\n The format for a JWS and standard claims included in it is specified by the IETF in RFC 7515 The signing algorithms for JSON Web tokens is specified by the IETF in RFC 7518 Encryption keys used for signing and validation are specified by the IETF in RFC 7517  There is another tool that was used to create this getting started guide, jose-util:\n JSON Web Token Signing and Encryption is commonly abbreviated as JOSE A command line utility called jose-util is available as part of a Golang JOSE library from Square To install it execute:   go get -u github.com/square/go-jose/jose-util   go install github.com/square/go-jose/jose-util  and make sure your go install directory is in your path    Use of this tool is optional since the tool has alredy been used and the results are already stored in the project.\nSimulated Scenario The scenario being simulated is a customer calling into a company to inquire about an order that they have placed. Various JWS tokens are used as a tamper resistent mechanism to communicate information about these participants through the API request chain.\nThe JSON Web Tokens The keys sub directory contains encryption keys that have been pre-created for you. If you would like to create new keys and have jose-util installed then run the script ./generate_keys.sh\nThe identities sub directory contains simulated identity tokens as JSON files. The script ./create_jws_tokens.sh can be used to sign and verify these tokens.\nProof of Authentication for an External Customer User A customer has called in to a company to enquire about an order that they have placed. The customer was authenticated by going through the Voice Response Unit (VRU) and evidence of that authentication is captured as a JWS token and is placed in the subject-token header. The customer identity provider performed the authentication. This token saves repeated database lookups and is used to authorize what the customer can do and has access to.\n The iss field contains the customer identity provider as the issuer. The profileRefID is a customer claim that can be used to get the customer\u0026rsquo;s preferences. The customerRefID is a custom claim that can be used to get details about the customer. The consentID is a custom claim that can be used to get details about what the customer has consented to and opted out from. The remaining claims are standard claims that contain information about the token issuance, use and authentication methods performed.  The full token is below:\n { \"iss\": \"customerIdentity.example.com\", \"sub\": \"customerIdentity:DBm4FBclSD261G2\", \"profileRefID\": \"34983598sfkh9w8798798d\", \"customerRefID\": \"DBm4FBclSD261G2\", \"consentID\": \"4378afd4f\", \"aud\": [ \"apigateway.example.com\", \"protected-stuff.example.com\"], \"azp\": \"app_123456\", \"exp\": 2735689600, \"iat\": 1597676718, \"auth_time\": 1597676718, \"jti\": \"o8T2hxraeFzIQ6p\", \"nonce\": \"n-0S6_WzA2Mj\", \"acr\": \"urn:mace:incommon:iap:silver\", \"amr\": [ \"face\", \"fpt\", \"geo\", \"mfa\" ], \"vot\": \"P1.Cc.Ac\", \"vtm\": \"https://example.org/vot-trust-framework\" }  Proof of Authentication for a Workforce User The call center agent was authenticated by the application she / he is using. Evidence of that authentication is captured as a JWS token is placed in the actor-token header. The workforce identity provider performed the authentication. This token saves repeated database lookups and is used to authorize what an agent can do on their own behalf as well as what an agent can do on the customer\u0026rsquo;s behalf.\n The iss field contains the workforce identity provider as the issuer. The remaining claims are standard claims that contain information about the token issuance, and use.  The full token is below:\n { \"iss\": \"workforceIdentity.example.com\", \"sub\": \"workforceIdentity:406319\", \"aud\": [ \"apigateway.example.com\", \"protected-stuff.example.com\"], \"azp\": \"app_123456\", \"exp\": 2735689600, \"iat\": 1597676718, \"auth_time\": 1597676718, \"jti\": \"mPPdwJ7Jrr2MQzS\" }  Proof of Authentication for an Application The application that the call center agent is using was authenticated by the API gateway. Proof of authentication and application details are placed in the app-token header. This stateless token saves repeated database lookups and is used for application level authorizations.\n The iss field contains the API gateway as the issuer. The client_id The remaining claims are standard claims that contain information about the token issuance, and use.  The full token is below:\n { \"iss\": \"apigateway.example.com\", \"sub\": \"apigateway:app_123456\", \"aud\": [ \"apigateway.example.com\", \"protected-stuff.example.com\"], \"azp\": \"app_123456\", \"client_id\": \"app_123456\", \"exp\": 2735689600, \"iat\": 1597676718, \"auth_time\": 1597676718, \"jti\": \"XcOpQe2vqTq1kny\", \"grant\": \"client_credentials\", \"owningLegalEntity\": \"Example Co.\", \"scopes\": [ \"rewards:read\", \"rewards:redeem\" ], \"kid\": \"APIGW-ES256\" }  Open Policy Agent Examples In the policy examples directory, there are 2 different REGO policies:\n jws_examples_v1.rego - which shows three diffent commands to process a JWS policy.rego - which shows our final policy  jws_examples_v1.rego  verify_example = { \"isValid\": isValid} { isValid := io.jwt.verify_es256(es256_token, jwks) }  The io.jwt.verify_xxx function simply checks to see if the signature on the token is valid. It returns a boolean indicating signature validity. It does not check the token claims. The downside of this function is that you must already know the algorithm used and then call the correct validation function.\n decode_example = {\"header\": header, \"payload\": payload, \"signature\": signature} { [header, payload, signature] := io.jwt.decode(es256_token) }  The io.jwt.decode() function does not validate the JWS. It base64 decodes the token and returns it\u0026rsquo;s constituent parts (header, payload and signature).\n decode_verify_example = { \"isValid\": isValid, \"header\": header, \"payload\": payload } { [isValid, header, payload] := io.jwt.decode_verify(es256_token, { \"cert\": jwks, \"iss\": \"xxx\", }) }  The io.jwt.decode_verify() function detects the correct algorithm from the JWS headers, validates the signature and validates the claims in the token. The second parameter for the decode and verify function is an object that contains the validation parameters. The cert property must be a string. A JSON web token keyset must be serialized to a string if you have it already read into memory as a parsed object. The other properties in the object are the expected token values. If an audience claim is specified in the token, then an audience claim must be specified in the parameter list. The audience claim is also assumed to be an array of strings. Audience claim validation checks for the presence of the supplied audience string anywhere in the audience claim array in the JWS.\nThe REGO policy in this file decodes the token using all 3 functions above and assigns them to the result.\n result = { \"verify_example\": verify_example, \"decode_example\": decode_example, \"decode_verify_example\": decode_verify_example }  The output below shows the result of executing the policy.\n { \"result\": [ { \"expressions\": [ { \"value\": { \"decode_example\": { \"header\": { \"alg\": \"ES256\", \"typ\": \"JWT\" }, \"payload\": { \"iss\": \"xxx\", \"nbf\": 1444478400 }, \"signature\": \"940adccdf37ea482fca1453eecf53cdeefb37d7a2e8170598fa76b15e285b0f128561cbd580ca266546c858aa34d25dd6b0f32c362fea2fb78cd35196f63d632\" }, \"decode_verify_example\": { \"header\": { \"alg\": \"ES256\", \"typ\": \"JWT\" }, \"isValid\": true, \"payload\": { \"iss\": \"xxx\", \"nbf\": 1444478400 } }, \"verify_example\": { \"isValid\": true } }, \"text\": \"data.jws.examples.v1.result\", \"location\": { \"row\": 1, \"col\": 1 } } ] } ] }  The policy_examples directory contains several scripts and rego policies that demonstrates 5 different ways to invoke our policy. The full suite of JWS signature validations are only performed in the first 4 techniques:\n policy_examples/run_rego_tests_locally.sh - This script runs the test policies with a locally installed Open Policy Agent. As you can see from this example, the output looks much like outpu from test runners in most other languages. policy_examples/run_rego_tests_in_docker.sh - This script runs the test policies using the Open Policy Agent docker container and a locally mapped volume The nice part about using this approach is that it doesn\u0026rsquo;t require anything installed locally other than docker. policy_examples/run_opa_cli.sh - This script uses eval statements to test policies using the Open Policy Agent docker container. It shows the results of using all 3 JWS functions io.jwt.verify_es256(), io.jwt.decode() and io.jwt.decode_verify() REGO commands in jws_examples_v1.rego. Additionally it shows using eval statements with our final policy.rego. You should see an output similar to this for each request. As you can see from this example and the REST API example that follows, the output from the eval statement approach and the REST API approach are a bit different. The eval statement technique returns a result object and an array of expression evalution objects. Within each of those objects is a value object that finally contains our results. policy_examples/run_opa_rest_decision_api_tests.sh - uses Curl commands and OPA\u0026rsquo;s REST API running in docker. The REST API has both a decision ID and the results in a results object. The decision ID can be used to with Open Policy Agent\u0026rsquo;s decision logs to find out more information about how the result was arrived at. demonstrate_opa_jws_validation.sh - This script uses the final solution that shows our fully integrated solution with Envoy. This script uses Curl to make requests to our target service. Envoy asks OPA for an authorization decision prior to forwarding to HTTPBIN. In the final result you can see the details of the curl request going into Envoy and the decision is implied from being able to see the response from the requested API or a 403 Forbidden response is given.  Conclusion The difficult part of getting this solution to work is tinkering required to get the Envoy configuration correct and understanding the idiosyncrasies of each of the Open Policy agent JWS functions. The purpose of this article is to shortcut that process for you by giving you a known good starting point with a working configuration and rego policy. Once you have a functioning example, it is easy to adapt the example to whatever your local use cases might be.\nIn the next getting started guide, we are going to show how you can also validate JWS tokens in Envoy without using OPA at. This gives you a choice to make about where you would like that authorization decision to be made.\n",
    "ref": "/blog/envoy_opa_5_opa_jws/"
  },{
    "title": "Using the Open Policy Agent CLI",
    "date": "September 2, 2020",
    "description": "Learn how to use Open Policy Agent Command Line Interface",
    "body": "Getting Started with Envoy \u0026amp; Open Policy Agent \u0026mdash; 04 \u0026mdash; Using the Open Policy Agent Command Line Interface This is the 4th Envoy \u0026amp; Open Policy Agent Getting Started Guide. Each guide is intended to explore a single feature and walk through a simple implementation. Each guide builds on the concepts explored in the previous guide with the end goal of building a very powerful authorization service by the end of the series.\nThe source code for this getting started example is located on Github. \u0026mdash;\u0026mdash;\u0026gt; Envoy \u0026amp; OPA GS # 4 \nHere is a list of the Getting Started Guides that are currently available.\nGetting Started Guides  Using Envoy as a Front Proxy Adding Observability Tools Plugging Open Policy Agent into Envoy Using the Open Policy Agent CLI JWS Signature Validation with OPA JWS Signature Validation with Envoy Putting It All Together with Composite Authorization  Installing Open Policy Agent Locally Intalling Open Policy Agent (OPA) is pretty simple. It is a very small executable and is entirely self contained with no other files required. Depending on your operating system, the command to install OPA is slightly different:\n Download the executable:   Mac OSX: curl -L -o opa https://openpolicyagent.org/downloads/latest/opa_darwin_amd64 Linux : curl -L -o opa https://openpolicyagent.org/downloads/latest/opa_linux_amd64  Give OPA permission to execute chmod 755 ./opa Move OPA somewhere in your path mv opa /somewhere/in/path  Using the CLI The Open Policy Agent command line interface is used for one of 3 different purposes:\n Using the OPA in interactive mode to write and evaluate REGO statements with realtime feedback after each statement Running policies by supplying a file for the input and another file with the policy to execute Starting OPA as a service to use it\u0026rsquo;s API for decisioning  Read Evaluate Print Loop (REPL) \u0026amp; Interactive Playground Interactive mode is sometimes referred to as a read-evaluate-print-loop (REPL). OPA will wait and read in input from a user. It will then evaluate the input and print the results of the evaluation for the user to see. It then loops through these steps over again until one of the statements that needs to be evaluated is the exit statement.\n To start using the OPA interactively simply enter the command opa run When you are ready to leave just enter the command exit  The Open Policy Agent web site has a nice tutorial for getting started with the REPL and interactively writing REGO policies. So, we won\u0026rsquo;t repeat that here. It is located at https://www.openpolicyagent.org/docs/latest/. The latest version of the getting started is an interactive notebook. So, you can edit the commands right on the web page and see the results.\nThere is also an interactive playground located at https://play.openpolicyagent.org/ It can be used to accomplish the same thing that we will demonstrate below. However, you probably don\u0026rsquo;t want to use these tools when you are writing your own policies. The logic of your policies may be confidential and proprietary and the data used in the policies may be confidential as well.\nUsing the CLI to evaluate a policy with some test data The Rego Policy\nFor this getting started example we will use the same policy that we created for Getting Started #3. It simply checks the request method and allows the request through if the Method is a GET operation.\nAn Allowed Input\nWe will also need to simulate an input that we expect will be allowed through. We are using the same data structure that Envoy sends us. Since we are only looking at the request Method, line 38 is only property that we are concerned about.\nRun the command\nTo run the policy with the input that we just covered, we use the eval subcommand as part of the OPA cli. We then need to pass in a few parameters:\n -i specifies the name of the file that we want to use as input -d specifies the name of the file contains the REGO policy that we want to run The last parameter is the query that we want to run. This was implied for us in the previous lesson since it a default is already baked into the containers that we used. In the command line below, we see that the query is data.envoy.authz.allow  opa eval -i ./data/allowed_input.json -d ./policies/policy.rego 'data.envoy.authz.allow'` The supplied bash script can save you some typing and will also run both the allowed example and the denied example.\n  This script saves you from having to install OPA locally. It runs OPA in docker. ./demonstrate_opa_cli_in_docker.sh\n  This script runs OPA locally../demonstrate_local_opa_cli.sh\n  The results\nAfter the command runs, you should see something like the image below. OPA returns a JSON Document with a results object and an array of processing results for expressions.\nUsing the CLI to execute REGO Tests Thankfully Open Policy Agent has a built in unit testing capability. It is really easy to use and will give you confidence when you are managing a large set of rules and periodically make changes to them. Just name your test file the same name as your policy with _test added to the base filename. Test are written in Rego just like the policies. We need to specify the same package name package envoy.authz as the policy that we are testing. Each test is actually a rego rule. The rego rule name must begin with the word test. The rest of the name should be descriptive of the test and expected result. e.g. test_get_allowed\nThe body of the rule is of the form:\n rule to run in the policy under test with input as simulated test input  Here is the test file that we have written to test our policy:\nAs you can see we simply drop in Envoy\u0026rsquo;s JSON input that we are testing and the result we expect (either allowed or not allowed). The highlighted property in each test data set shows the only value that we are looking for in our rules:\n The allowed test case has a GET method in the test data The not allowed test case has a POST which falls into the the set of all methods other than GET are not allowed  Using the API Interactively to Develop Policies OPA policy agent also supports running as a service and accessing it via REST APIs. Detailed API information can be found on the Open Policy Agent web site. Here is a summary of the APIs.\nPolicy API for Creating, Updating or Deleting Policies\n  GET /v1/policies #--- List Policies    GET /v1/policies/\u0026ltid\u0026gt #--- Get a specific Policy    PUT /v1/policies/\u0026ltid\u0026gt #--- Create or Update a Policy    DELETE /v1/policies/\u0026ltid\u0026gt #--- Delete a policy    Data API for Creating, Updating or Deleting Data and Getting Decisions\n  GET /v1/data/{path:.+} #--- Get a Document    POST /v1/data/{path:.+} #--- Get a Document (with Input e.g. get a decision). The input document `{ \"input\": ... }` is passed in the request body   PUT /v1/data/{path:.+} #--- Create or Overwrite a Document    PATCH /v1/data/{path:.+} #--- Patch a Document    DELETE /v1/data/{path:.+} #--- Delete a Document    Tips when using the API\n It is important to understand how the OPA document model works. The document model is described on the Open Policy Agent web site. Attempting to delete everything by supplying the root path for the policy or data endpoint doesn\u0026rsquo;t delete everything. This makes sense after thinking about it. It would be very easy to accidentally clear out an entire OPA engine and un-intentionally cause an outage if that was done in production. Even though all of the policies are visiable in the data endpoint when queried, they can\u0026rsquo;t be created, deleted or modified using that endpoint. It is mearly a way of invoking the policy and getting a decision. (see the policy in the highlighted section below)  Even though data and policies can be loaded in the same data document tree, it is confusing and not recommended (e.g. I deleted that data why is it still there? Oh, that\u0026rsquo;s because it is a policy and can\u0026rsquo;t be deleted by the data API):  /v1/data/{packagename}/{data document name} /v1/data/{packagename}/{policy rule name}   A clearer approach is to have a reference data and policy path like this:  /v1/data/reference/{data document path and name} /v1/data/app/{packagename}/{policy rule name}   The Policy API will store a policy with any provided key. However, it is loaded into the global data document based on its package name. Using the package name as the policy ID is an intuitive way to refer to policies. The policy ID field supports forward slashes. Be careful When assigning calculated or lookup values to a variable that you want to return in the result set. OPA will not return an undefined value in a property of a JSON document. An undefined value will fail the entire rule and cause OPA to return an empty object if no statically defined default is specified.  Producing Reason Codes with REGO Sometimes it is desirable for debugging or for audit or regulatory purposes to capture a reason code for decision results (usually denial reason but sometime approval too ). The OPA playground has a pet shop app example. It can be found in the REGO playground. Just select the attribute based access control example from the drop down menu.\nThe example below is modified to provide approval reasons and other messages in the case of a denial to help understand why access was denied. Logical OR conditions are expressed by creating multiple rules with the same name. The first 4 allow rules below are various reasons to approve the access request. If any of these rules is true the response is set to a static object with the approval decision and the reason code. The 5th allow rule is intended fire only when all of the approval rules fail. It is intended to give us insight into why the access request was denied. So this rule tests to see if all of the other rules fail.\nTo make sure the approval rules and deny rule don\u0026rsquo;t get out of sync, they both point to named approval rules below.\nThe messaging section is similar to the logical OR approval rules above. However they are structured a little bit differently. The square brackets enable these rules to return an array / collection of results. Unlike other data types where an undefined value will cause the rule to fail, it will return an empty array if none of the rules triggers the population of a message.\nWith these changes we now have insight into the output of the rules. In the example below, we send in a request with an un-registered user. If more insight is needed there is also the option to add the explain = full parameter to see a trace of the rule execution. The response field shows the results with provenance, explanation, metrics, and the messages that indicate which rules failed.\nThe images below zoom in on the explaination returned. The highlighted sections shows the step by step rule execution and where the rule failures occurred. On the left hand side is a reference to the exact line number in the rego file where the rule failure occurred. Any rule that results in an \u0026lsquo;undefined\u0026rsquo; state is considered a failure.\nExploring the OPA API with a sample Postman collection To make it easier to explore the OPA APIs, a postman collection pre-populated with the example data and policy is included with the rest of the code in the github repository.\nUploading the Pet Store App ABAC Policy via Postman\nUploading the Pet Store App Reference Data\nExploring the OPA API with a sample bash script If you don\u0026rsquo;t already use Postman, another option to explore the OPA APIs that does not require a large install is to use the included bash script. Simply run demonstrate_opa_api_in_docker.sh\nCongratulations! We have walked through how to use the OPA CLI, test REGO policies and use the OPA REST API. With the basics under your belt, we can move on to more sophisticated use cases such as Signed JSON Web Token (JWS) validation.\n",
    "ref": "/blog/envoy_opa_4_opa_cli/"
  },{
    "title": "Plugging Open Policy Agent into Envoy",
    "date": "September 1, 2020",
    "description": "Learn how to use Open Policy Agent with Envoy for more powerful authorization rules",
    "body": "Photo by Kutan Ural on Unsplash\nGetting Started with Envoy \u0026amp; Open Policy Agent \u0026mdash; 03 \u0026mdash; Plugging OPA into Envoy This is the 3rd Envoy \u0026amp; Open Policy Agent Getting Started Guide. Each guide is intended to explore a single feature and walk through a simple implementation. Each guide builds on the concepts explored in the previous guide with the end goal of building a very powerful authorization service by the end of the series.\nAll of the source code for this getting started example is located on github. \u0026mdash;\u0026mdash;\u0026gt; Envoy \u0026amp; OPA GS # 3 \nHere is a list of the Getting Started Guides that are currently available.\nGetting Started Guides  Using Envoy as a Front Proxy Adding Observability Tools Plugging Open Policy Agent into Envoy Using the Open Policy Agent CLI JWS Signature Validation with OPA JWS Signature Validation with Envoy Putting It All Together with Composite Authorization  Envoy\u0026rsquo;s External Authorization API Envoy has the capability to call out to an external authorization service. There are 2 protocols supported. The authorization service can be either a RESTful API endpoint or using Envoy\u0026rsquo;s new gRPC protocol. Envoy sends all of the request details to the authorization service including the method, URI, parameters, headers, and request body. The authorization service simply needs to return 200 OK to permit the request to go through.\nIn this example we will be using a pre-built Open Policy Agent container that already understands Envoy\u0026rsquo;s authorization protocol.\nOpen Policy Agent Overview The Open Policy Agent site describes it very succinctly\nThe Open Policy Agent (OPA) is an open source, general-purpose policy engine. OPA provides a declarative language that letâ€™s you specify policy as code and APIs to offload policy decision-making from your software. OPA to enforce policies in microservices, Kubernetes, CI/CD pipelines, API gateways, or nearly any other software.\nOPA focuses exclusively on making policy decisions and not on policy enforcement. OPA pairs with Envoy for policy enforcement. OPA can run as:\n A standalone service accessible via an API A library that can be compiled into your code  It has an extremely flexible programming model:\nAdditionally, the company behind OPA, Styra, offers control plane products to author policies and manage a fleet of OPA instances.\nOPA decouples policy decision-making from policy enforcement. When your software needs to make policy decisions it queries OPA and supplies structured data (e.g., JSON) as input. OPA accepts arbitrary structured data as input.\nOPA generates policy decisions by evaluating the query input against policies and data. OPA expresses policies in a language called Rego. OPA has exploded in popularity and has become a Cloud Native Computing Foundation incubating project. Typical use cases are deciding:\n Which users can access which resources Which subnets egress traffic is allowed Which clusters a workload can be deployed to Which registries binaries can be downloaded from Which OS capabilities a container can execute with The time of day the system can be accessed  Policy decisions are not limited to simple yes/no or allow/deny answers. Policies can generate any arbitrary structured data as output.\nThis getting started example is based on this OPA tutorial using docker-compose instead of Kubernetes.\nSolution Overview In this getting started example we take the super simple envoy environment we created in getting started episode 1 and add the simplest possible authorization rule using Open Policy Agent.\nDocker Compose This is the same docker compose file as our initial getting started example with a few modifications. At line 15 in our docker-compose file, we added a reference to our Open Policy Agent container. This is a special verison of the Open Policy Agent containers on dockerhub. This version is designed to integrate with Envoy and has an API exposed the complies with Envoy\u0026rsquo;s gRPC specification. There are also some other things to take notice of:\n Debug level logging is set on line 21 The gRPC service for Envoy is configured on line 23 The logs are sent to the console for a log aggregation solution to pickup (or not) on line 24  Envoy Config Changes There are a few things that we need to add to the envoy configuration to enable external authorization:\n We added an external authorization configuration at line 23. failure_mode_allow on line 26 determines whether envoy fails open or closed when the authorization service fails. with_request_body determines if the request body is sent to the authorization service. max_request_bytes determines how large of a request body Envoy will permit. allow_partial_message determines if a partial body is sent or not when a buffer maximum is reached. The grpc_service object on line 30 specifies how to reach the Open Policy Agent endpoint to make an authorization decision.  Rego: OPA\u0026rsquo;s Policy Language There are a lot of other examples of how to write Rego policies on other sites. This walkthrough of Rego is targeted specifically to using it to make Envoy decisions:\n The package statement on the first line determines where the policy is located in OPA. When a policy decision is requested, the package name is used as the prefix used to locate the named decision. The import statement on line 3 navigates the heavily nested data structure that Envoy sends us and gives us a shorter alias to refer to a particular section of the input. On line 5 we have a rule named allow and we set it\u0026rsquo;s default value to and object that Envoy is expecting.  The allowed property determines if the request is permitted to go through or not. The headers property allows us to set headers on either the forwarded request (if approved) or on the rejected request (if denied). OPA does not marshal any REGO data types on your behalf. All header values must be specified as a string. The body property can be used to communicate error message details to the requestor. It has no affect on requests approved for forwarding. OPA does not marshal any REGO data types on your behalf. The body value must be specified as a string. The http_status property can be set on any rejected requests to any value as desired   The next section starting at line 12 specifies the logic for approving the request to move forward  On line 12 the allow rule is set to the value of the response variable that we define in the body of the rule Line 13 is the only condition we have defined for approval of the request. The request method simply needs to be a POST. If true then we set the response to the values on lines 15 and 16.    Input data sent from Envoy Now we dive into the details of the input data structure sent from Envoy.\n Line 3 is an object that describes the IP address and Port that the request is going to Line 10 is the request object itself. The unmarshalled body is present along with:  request headers hostname where the original request was sent a unique request ID assigned by Envoy request method unparsed path protocol request size   Line 34 is a object that describes the IP address and port where the request originated Line 45 is where Envoy has already done some work for us to parse the request body (if it was configured to be forwarded) Line 46 and 47 are the parsed path and query parameters respectively Finally, line 48 let\u0026rsquo;s us know whether we have the complete request body or not  Reviewing the Request Flow in Envoy\u0026rsquo;s Logs In debug mode, we have a lot of rich information that Envoy logs for us to help us determine what may be going wrong as we develop our system.\n Line 1 shows our request first coming in The next several lines show us the request headers Line 13-14 let\u0026rsquo;s us know that envoy is buffering the request until it reaches the buffer limit that we set Line 16-20 show us that Envoy forwarded the request to our authorization service and got an approval to forward the request The remainder of the logs show envoy forwarding the request to its destination and then back to the calling client  Reviewing OPA\u0026rsquo;s Decision Log The open policy agent decision logs include the input that we just reviewed and some other information that we can use for debugging, troubleshoot or audit logging. The interesting parts that we haven\u0026rsquo;t reviewed yet:\n The decision ID on line 2 can be matched against other OPA log entries related to this decision Line 5 - Envoy sends us the destination of the request Line 7 - Envoy sends the request details. The unmarshalled body is only available if we setup the buffering and forwarding in the Envoy configuration. line 30 - Envoy also sends us the source IP address that it received the request from. Line 37 has the labels that show which Envoy instance the request came from Line 42 is an object that contains the performance metrics for the decision Line 50 shows the response that OPA sent back to Envoy  Taking this solution for a spin Now that we know what we are looking at, we can run this example by executing the script ./demonstrate_opa_integration.sh\n The script starts the envoy front proxy, HTTPBIN and Open Policy Agent Next it shows the docker container status to make sure everything is up and running. Curl is used to issue a request that should get approved, forwarded to HTTPBin and the display the results The opa decision logs are then shown to let you explore the information available for development debugging and troubleshooting To make sure we show both outcomes the next request should fail our simple authorization rule check. The decision logs are shown again Finally the example is brought down and cleaned up.  In the next getting started guide we will explore Open Policy Agent\u0026rsquo;s command line interface and unit testing support.\n",
    "ref": "/blog/envoy_opa_3_adding_open_policy_agent/"
  },{
    "title": "Adding Observability Tools",
    "date": "September 1, 2020",
    "description": "Learn how to add ElasticSearch and Kibana to your Envoy front proxy environment",
    "body": "Photo by Alex Eckermann on Unsplash\nGetting Started with Envoy \u0026amp; Open Policy Agent \u0026mdash; 02 \u0026mdash; Adding Log Aggregation to our Envoy Example This is the 2nd Envoy \u0026amp; Open Policy Agent (OPA) Getting Started Guide. Each guide is intended to explore a single Envoy or OPA feature and walk through a simple implementation. Each guide builds on the concepts explored in the previous guide with the goal of creating a very powerful authorization service by the end of the series.\nWhile our solution is still very simple, it is a great time to show how to make our solution observable with log aggregation. This makes it easier to think about how to scale and productionize our solution. As we start to develop and apply authorization rules at scale it will be handy to have all of the logs aggregated and displayed in one place for development and troubleshooting activies. In this article we will walk through how to setup the EFK stack to pull your logs together from all of the docker containers in your local development environment.\nAll of the source code for this getting started example is located on github. \u0026mdash;\u0026mdash;\u0026gt; Envoy \u0026amp; OPA GS # 2 \nHere is a list of the Getting Started Guides that are currently available.\nGetting Started Guides  Using Envoy as a Front Proxy Adding Observability Tools Plugging Open Policy Agent into Envoy Using the Open Policy Agent CLI JWS Signature Validation with OPA JWS Signature Validation with Envoy Putting It All Together with Composite Authorization  Solution Overview The solution that we will build in this blog is shown below. We will send docker logs into an EFK stack that is also running inside docker. Each of the containers in our solution simply send logs to Standard out and / or Standard Error. No agents nor other special software is requirements are imposed on the observered applications.\nAdding EFK containers We will be using Fluent Bit in this example because it is lite weight and simpler to deal with than Logstash or full fledged FluentD. Below is a very basic configuration with no special optimizations. Lines 18 - 49 add the EFK stack to our environment. Lines 16 and 47 use the depend_on property to cause docker to start elasticSearch first and then Kiban and Fluent Bit that depend on elasticSearch.\nWiring our containers into EFK With the EFK log aggregation containers added to our docker-compose file, we now need to wire them into the other containers in our environment. The changes below show a couple of small changes that we needed to make to our compose file from where we left off in Getting Started Guide #1. We added the property at line 14 below which expresses our dependency on elasticSeach. Additionally, we need to wire standard out and standard error from our containers to Fluent Bit. This is done through the logging properties on lines 17 and 27. The driver line tells docker which log driver to use and the tag help make it more clear which container is the source of the logs.\nTaking things for a spin The demonstration script spins everything up for us. Just run ./demonstrate_front_proxy.sh to get things going:\n It downloads and spins up all of our containers. Then it waits 30 seconds to give elasticSearch some time to get ready and some time for Kibana to know that elasticSearch is ready. A curl command sends Envoy a request to make sure the end-to-end flow is working. If that worked, proceed forward. If not wait a bit longer to make sure elasticSearch and Kibana are both ready. If you are running on Mac OS X then the next step will open a browser and take you to the page to setup your Kibana index. If it doesn\u0026rsquo;t work, simply open your browser and go to http://localhost:5601/app/kibana#/management/kibana/index_pattern?_g=() you should see something like this:  I simply used log* as my index and clicked next. Which should bring up a screen to select the timestamp field name. Select @timestamp and click create index. You should see some field information about your newly created index.  The script then uses the Open command to navigate to the log search interface. If it doesn\u0026rsquo;t work on your operating system then simply navigate to http://localhost:5601/app/kibana#/discover. You should see something like this with some log results already coming in. If you have an interest, you may want to select the container_name and log columns to make it easier to read through the debug logs and results of your testing efforts.  The script sends another request through envoy and you should be able to see the logs coming into EFK.  The script with then take down the environment.  In the next getting started guide, we will add in Open Policy Agent and begin experimenting with a simple authorization rule.\n",
    "ref": "/blog/envoy_opa_2_adding_observability/"
  },{
    "title": "Using Envoy as a Front Proxy",
    "date": "August 31, 2020",
    "description": "Learn how to set up Envoy as a front proxy with docker",
    "body": "Photo by Mattia Serrani on Unsplash\nGetting Started with Envoy \u0026amp; Open Policy Agent \u0026mdash; 01 \u0026mdash; Using Envoy as a Front Proxy This is the 1st Envoy \u0026amp; Open Policy Agent (OPA) Getting Started Guide. Each guide is intended to explore a single Envoy or OPA feature and walk through a simple implementation. Each guide builds on the concepts explored in the previous guide with the end goal of building a very powerful authorization service by the end of the series.\nThe source code for this getting started example is located on Github. \u0026mdash;\u0026mdash;\u0026gt; Envoy \u0026amp; OPA GS # 1 \nHere is a list of the Getting Started Guides that are currently available.\nGetting Started Guides  Using Envoy as a Front Proxy Adding Observability Tools Plugging Open Policy Agent into Envoy Using the Open Policy Agent CLI JWS Signature Validation with OPA JWS Signature Validation with Envoy Putting It All Together with Composite Authorization  Overview Envoy is an open source edge and service proxy that has become extremely popular as the backbone underneath most of the leading service mesh products (both open source and commercial). This article is intended to demystify it a bit and help people understand how to use it on it\u0026rsquo;s own in a minimalist fashion.\nEnvoy is just like any other proxy. It receives requests and forwards them to services that are located behind it. The 2 ways to deploy Envoy are:\n  Front Proxy - In a front proxy deployment Envoy is very similar to NGINX, HAProxy, or an Apache web server. The Envoy server has it\u0026rsquo;s own IP address and is a separate server on the network from the services that it protects. Traffic comes in and get forwarded to a number of different services that are located behind it. Envoy supports a variety of methods for making routing decisions.\n One mechanism is to use path based routing to determine the service of interest. For instance a request coming in as: /service1/some/other/stuff can use the first uri path element as a routing key. service1 can be used to route requests to service 1. Additionally, service2 in /service2/my/applications/path can be used to route the request to a set of servers that support service 2. The path can be rewritten as it goes through Envoy to trim off the service routing prefix. Another mechanism is to use Server Name Indication (SNI) which is a TLS extension to determine where to forward a request. Using this technique, service1.com/some/other/stuff would use the server name to route to the service1 services. Additionally, service2.com/my/applications/path would use service2.com to route the request to service2. The diagram above shows the front proxy approach.    Sidecar Proxy - In a sidecar deployment, the Envoy server is located at the same IP address as each service that it protects. The Envoy server when deployed as as sidecar only has a single service instance behind it. The sidecar approach can intercept all inbound traffic and optionally all outbound traffic on behalf of the service instance. IP Tables rules are typically used to configure the operating system to capture and redirect this traffic to Envoy. The diagram above shows the sidecar approach.\n  In this article and example project we will start with the simplest possible Envoy deployment. This example just uses docker compose to show how to get Envoy up and running. There will be a number of subsequent articles that expand on this simple approach to demostrate more Envoy capabilies. Open Policy Agent will also be introduced to handle more complex authorization use cases that cannot be handled by Envoy alone.\nThe diagram below shows the environment that we are about to build and deploy locally.\nBuilding an Envoy Front Proxy The code for the complete working example can be found on Github. We will start with the Envoy docker images. The Envoy images are located on Dockerhub. We will use docker-compose to build some configurability into our Envoy environment.\nDockerfile The entrypoint.sh file is where the magic happens. We will configure environment variables in our docker-compose file to determine which service (SERVICE_NAME) Envoy routes to and the port (SERVICE_PORT) on that service. Additionally, we specify how much detail is captured in the logs by setting the DEBUG_LEVEL environment variable. As you can see from the script below on line 3, we replace those environment variables on the fly in Envoy\u0026rsquo;s configuration file before starting Envoy.\nentrypoint.sh Since we don\u0026rsquo;t have a configuration file yet, we will cover that next. Envoy is very flexible and powerful. There is an enormous amount of expressiveness that the Envoy API and configuration files support. With this flexibility and power, Envoy configuration files can become quite complicated with a lot layers in the YAML hierarchy. Additionally, each feature has a lot of configuration parameters. The documentation can only cover so much of that functionality with an open source community of volunteers.\nOne of the challenges that I have when reading through the documentation and trying to apply it, is that the documentation has a variety of YAML snippets. There are very few places that these YAML snippets are pulled together into a functioning example. There are a few examples in the source code examples directory but they are far from comprehensive. That leaves a lot of tinkering for engineers to figure out how to compose a functional configuration while interpretting sometimes unclear error messages on their way to the promised land. That is the entire reason that I am writting a series of getting started guides. These articles are intended to give folks a known to work starting point for Envoy authorization features and extensions like Open Policy Agent.\nThe Envoy configuration starts with defining a listener as we can see starting on line 3. The first property is the address and port to accept traffic on (lines 3 through 6). The next property is a filter chain. Filter chains are very powerful and enable configuration for a wide variety of possible behaviors. This filter chain is as simple as it gets. It simply accepts any HTTP traffic with any URI pattern and routes it to the cluster named service.\nThe http_connection_manager component does this for us. It\u0026rsquo;s configuration starts on line 9 and extends to line 24. Execution order is determined by the order they are listed in the configuration file. The important part for this discussion begins on line 14 with the route_config. This sets up routing requests for any domain (line 18) and any request URI that begins with a slash (line 20) to go to the cluster named service. The cluster definitions are in a separate section to make them reusable destination across a variety of rules.\nEnvoy Configuration (envoy.yaml) The cluster definitions begin on line 25. We can see that there is only a single cluster defined. It has the name service, uses DNS to find server instances and uses round robin to direct traffic across multiple instances. The hostname is on line 32 and the port is on line 33. As we can see these are the environment variables that we will swap out with the entry.sh script.\nThe last section of the configuration file tells Envoy where to listen for admin traffic. The admin gui is a handy little tool that we will not cover in this guide but is definitely worth poking around in to observe what is going on inside an individual Envoy instance.\nDocker Compose Configuration Now that we understand the Envoy configuration we can move on to understanding the rest of the simple environment that we are setting up. Line 4 shows the trigger that causes docker to build the Envoy container. Docker will only build the Envoy Dockerfile the first time it sees that an image does not exist. If you want to force rebuilding the Envoy container on subsequent runs add the --build parameter to your docker compose command. We expose Envoy to the host network on lines 6 and 7 and provide the configuration file that we just created on line 9.\nThe service to route to and port are defined on the environment variables on lines 12 and 13. Notice the name app matches the name of our final service on line 15. We are simply using HTTPBIN to reflect our request back to us.\nRunning and Trying out our Example The last step to getting our front proxy up is simply running the included script test.sh that demonstrates our example. The script explains what it is about to do to ensure you know what are about to see scrolling across your terminal screen. Line 3 starts our environment. Line 8 let\u0026rsquo;s you check to make sure both containers are running before trying to send them a request.\nLine 10 simply calls Envoy with a curl command with the --verbose parameter set so that you can see the headers and request details. Then line 12 tears down the whole environment.\nContainers UP!!!! If you have successfully started your environment then you should see something like this:\nWe Succeeded!!! You should see something like this if you successfully called HTTPBin through Envoy:\nCongratulations Congratulations, you have successully stood up your first Envoy instance and configured it to forward traffic! This is the simplest possible Envoy configuration :) We don\u0026rsquo;t have any security yet or any other features that Envoy is famous for. We will get to that in future articles. Feel free to use postman to explore other requests that you can send. Additionally, don\u0026rsquo;t forget to explore Envoy\u0026rsquo;s admin console by pointing your web browser to http://localhost:8001\n",
    "ref": "/blog/envoy_opa_1_front_proxy/"
  },{
    "title": "About",
    "date": "February 28, 2019",
    "description": "Helpful Badger, searching the world for helpful tech tips",
    "body": "Photo by Vincent van Zalinge on Unsplash\nThe Helpful Badger loves technology. He travels the world looking for interesting technology topics and shares his perspective on what he finds.\nIf you see him out it the woods seeking his next adventure, offer him a StarBucks Pike Place coffee. He\u0026rsquo;ll gladly pull up a chair and talk tech with you!\n",
    "ref": "/about/"
  }]
