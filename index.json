[{
    "title": "Using the Open Policy Agent CLI",
    "date": "September 2, 2020",
    "description": "Learn how to use Open Policy Agent Command Line Interface",
    "body": "Getting Started with Envoy \u0026amp; Open Policy Agent \u0026mdash; 04 \u0026mdash; Using the Open Policy Agent Command Line Interface This is the 4th Envory \u0026amp; Open Policy Agent Getting Started Guide. Each guide is intended to explore a single feature and walk through a simple implementation. Each guide builds on the concepts explored in the previous guide with the end goal of building a very powerful authorization service by the end of the series.\nThe source code for this getting started examples is located on Github. \u0026mdash;\u0026mdash;\u0026gt; Envoy \u0026amp; OPA GS # 4 \nHere is a list of the Getting Started Guides that are currently available.\nGetting Started Guides  Using Envoy as a Front Proxy Adding Observability Tools Plugging Open Policy Agent into Envoy Using the Open Policy Agent CLI  Installing Open Policy Agent Locally Intalling Open Policy Agent (OPA) is pretty simple. It is a very small executable and is entirely self contained with no other files required. Depending on your operating system, the command to install OPA is slightly different:\n Download the executable:   Mac OSX: curl -L -o opa https://openpolicyagent.org/downloads/latest/opa_darwin_amd64 Linux : curl -L -o opa https://openpolicyagent.org/downloads/latest/opa_linux_amd64  Give OPA permission to execute chmod 755 ./opa Move OPA somewhere in your path mv opa /somewhere/in/path  Using the CLI The Open Policy Agent command line interface is used for one of 3 different purposes:\n Using the OPA in interactive mode to write and evaluate REGO statements with realtime feedback after each statement Running policies by supplying a file for the input and another file with the policy to execute Starting OPA as a service to use it\u0026rsquo;s API for decisioning  Read Evaluate Print Loop (REPL) \u0026amp; Interactive Playground Interactive mode is sometimes referred to as a read-evaluate-print-loop (REPL). OPA will wait and read in input from a user. It will then evaluate the input and print the results of the evaluation for the user to see. It then loops through these steps over again until one of the statements that needs to be evaluated is the exit statement.\n To start using the OPA interactively simply enter the command opa run When you are ready to leave just enter the command exit  The Open Policy Agent web site has a nice tutorial for getting started with the REPL and interactively writing REGO policies. So, we won\u0026rsquo;t repeat that here. It is located at https://www.openpolicyagent.org/docs/latest/. The latest version of the getting started is an interactive notebook. So, you can edit the commands right on the web page and see the results.\nThere is also an interactive playground located at https://play.openpolicyagent.org/ It can be used to accomplish the same thing that we will demonstrate below. However, you probably don\u0026rsquo;t want to use these tools when you are writing your own policies. The logic of your policies may be confidential and proprietary and the data used in the policies may be confidential as well.\nUsing the CLI to evaluate a policy with some test data The Rego Policy\nFor this getting started example we will use the same policy that we created for Getting Started #3. It simply checks the request method and allows the request through if the Method is a GET operation.\nAn Allowed Input\nWe will also need to simulate an input that we expect will be allowed through. We are using the same data structure that Envoy sends us. Since we are only looking at the request Method, line 38 is only property that we are concerned about.\nRun the command\nTo run the policy with the input that we just covered, we use the eval subcommand as part of the OPA cli. We then need to pass in a few parameters:\n -i specifies the name of the file that we want to use as input -d specifies the name of the file contains the REGO policy that we want to run The last parameter is the query that we want to run. This was implied for us in the previous lesson since it a default is already baked into the containers that we used. In the command line below, we see that the query is data.envoy.authz.allow  opa eval -i ./data/allowed_input.json -d ./policies/policy.rego 'data.envoy.authz.allow'` The supplied bash script can save you some typing and will also run both the allowed example and the denied example.\n  This script saves you from having to install OPA locally. It runs OPA in docker. ./demonstrate_opa_cli_in_docker.sh\n  This script runs OPA locally../demonstrate_local_opa_cli.sh\n  The results\nAfter the command runs, you should see something like the image below. OPA returns a JSON Document with a results object and an array of processing results for expressions.\nUsing the CLI to execute REGO Tests Thankfully Open Policy Agent has a built in unit testing capability. It is really easy to use and will give you confidence when you are managing a large set of rules and periodically make changes to them. Just name your test file the same name as your policy with _test added to the base filename. Test are written in Rego just like the policies. We need to specify the same package name package envoy.authz as the policy that we are testing. Each test is actually a rego rule. The rego rule name must begin with the word test. The rest of the name should be descriptive of the test and expected result. e.g. test_get_allowed\nThe body of the rule is of the form:\n rule to run in the policy under test with input as simulated test input  Here is the test file that we have written to test our policy:\nAs you can see we simply drop in Envoy\u0026rsquo;s JSON input that we are testing and the result we expect (either allowed or not allowed). The highlighted property in each test data set shows the only value that we are looking for in our rules:\n The allowed test case has a GET method in the test data The not allowed test case has a POST which falls into the the set of all methods other than GET are not allowed  Using the API Interactively to Develop Policies OPA policy agent also supports running as a service and accessing it via REST APIs. Detailed API information can be found on the Open Policy Agent web site. Here is a summary of the APIs.\nPolicy API for Creating, Updating or Deleting Policies\n  GET /v1/policies #--- List Policies    GET /v1/policies/\u0026ltid\u0026gt #--- Get a specific Policy    PUT /v1/policies/\u0026ltid\u0026gt #--- Create or Update a Policy    DELETE /v1/policies/\u0026ltid\u0026gt #--- Delete a policy    Data API for Creating, Updating or Deleting Data and Getting Decisions\n  GET /v1/data/{path:.+} #--- Get a Document    POST /v1/data/{path:.+} #--- Get a Document (with Input e.g. get a decision). The input document `{ \"input\": ... }` is passed in the request body   PUT /v1/data/{path:.+} #--- Create or Overwrite a Document    PATCH /v1/data/{path:.+} #--- Patch a Document    DELETE /v1/data/{path:.+} #--- Delete a Document    Tips when using the API\n It is important to understand how the OPA document model works. The document model is described on the Open Policy Agent web site. Attempting to delete everything by supplying the root path for the policy or data endpoint doesn\u0026rsquo;t delete everything. This makes sense after thinking about it. It would be very easy to accidentally clear out an entire OPA engine and un-intentionally cause an outage if that was done in production. Even though all of the policies are visiable in the data endpoint when queried, they can\u0026rsquo;t be created, deleted or modified using that endpoint. It is mearly a way of invoking the policy and getting a decision. (see the policy in the highlighted section below)  Even though data and policies can be loaded in the same data document tree, it is confusing and not recommended (e.g. I deleted that data why is it still there? Oh, that\u0026rsquo;s because it is a policy and can\u0026rsquo;t be deleted by the data API):  /v1/data/{packagename}/{data document name} /v1/data/{packagename}/{policy rule name}   A clearer approach is to have a reference data and policy path like this:  /v1/data/reference/{data document path and name} /v1/data/app/{packagename}/{policy rule name}   The Policy API will store a policy with any provided key. However, it is loaded into the global data document based on its package name. Using the package name as the policy ID is an intuitive way to refer to policies. The policy ID field supports forward slashes. Be careful When assigning calculated or lookup values to a variable that you want to return in the result set. OPA will not return an undefined value in a property of a JSON document. An undefined value will fail the entire rule and cause OPA to return an empty object if no statically defined default is specified.  Producing Reason Codes with REGO Sometimes it is desirable for debugging or for audit or regulatory purposes to capture a reason code for decision results (usually denial reason but sometime approval too ). The OPA playground has a pet shop app example. It can be found in the REGO playground. Just select the attribute based access control example from the drop down menu.\nThe example below is modified to provide approval reasons and other messages in the case of a denial to help understand why access was denied. Logical OR conditions are expressed by creating multiple rules with the same name. The first 4 allow rules below are various reasons to approve the access request. If any of these rules is true the response is set to a static object with the approval decision and the reason code. The 5th allow rule is intended fire only when all of the approval rules fail. It is intended to give us insight into why the access request was denied. So this rule tests to see if all of the other rules fail.\nTo make sure the approval rules and deny rule don\u0026rsquo;t get out of sync, they both point to named approval rules below.\nThe messaging section is similar to the logical OR approval rules above. However they are structured a little bit differently. The square brackets enable these rules to return an array / collection of results. Unlike other data types where an undefined value will cause the rule to fail, it will return an empty array if none of the rules triggers the population of a message.\nWith these changes we now have insight into the output of the rules. In the example below, we send in a request with an un-registered user. If more insight is needed there is also the option to add the explain = full parameter to see a trace of the rule execution. The response field shows the results with provenance, explanation, metrics, and the messages that indicate which rules failed.\nThe images below zoom in on the explaination returned. The highlighted sections shows the step by step rule execution and where the rule failures occurred. On the left hand side is a reference to the exact line number in the rego file where the rule failure occurred. Any rule that results in an \u0026lsquo;undefined\u0026rsquo; state is considered a failure.\nExploring the OPA API with a sample Postman collection To make it easier to explore the OPA APIs, a postman collection pre-populated with the example data and policy is included with the rest of the code in the github repository.\nUploading the Pet Store App ABAC Policy via Postman\nUploading the Pet Store App Reference Data\nExploring the OPA API with a sample bash script If you don\u0026rsquo;t already use Postman, another option to explore the OPA APIs that does not require a large install is to use the included bash script. Simply run demonstrate_opa_api_in_docker.sh\nCongratulations! We have walked through how to use the OPA CLI, test REGO policies and use the OPA REST API. With the basics under your belt, we can move on to more sophisticated use cases such as Signed JSON Web Token (JWS) validation.\n",
    "ref": "/blog/envoy_opa_4_opa_cli/"
  },{
    "title": "Plugging Open Policy Agent into Envoy",
    "date": "September 1, 2020",
    "description": "Learn how to use Open Policy Agent with Envoy for more powerful authorization rules",
    "body": "Photo by Kutan Ural on Unsplash\nGetting Started with Envoy \u0026amp; Open Policy Agent \u0026mdash; 03 \u0026mdash; Plugging OPA into Envoy This is the 3rd Envory \u0026amp; Open Policy Agent Getting Started Guide. Each guide is intended to explore a single feature and walk through a simple implementation. Each guide builds on the concepts explored in the previous guide with the end goal of building a very powerful authorization service by the end of the series.\nAll of the source code for this getting started example is located on github. \u0026mdash;\u0026mdash;\u0026gt; Envoy \u0026amp; OPA GS # 3 \nHere is a list of the Getting Started Guides that are currently available.\nGetting Started Guides  Using Envoy as a Front Proxy Adding Observability Tools Plugging Open Policy Agent into Envoy Using the Open Policy Agent CLI  Envoy\u0026rsquo;s External Authorization API Envoy has the capability to call out to an external authorization service. There are 2 protocols supported. The authorization service can be either a RESTful API endpoint or using Envoy\u0026rsquo;s new gRPC protocol. Envoy sends all of the request details to the authorization service including the method, URI, parameters, headers, and request body. The authorization service simply needs to return 200 OK to permit the request to go through.\nIn this example we will be using a pre-built Open Policy Agent container that already understands Envoy\u0026rsquo;s authorization protocol.\nOpen Policy Agent Overview The Open Policy Agent site describes it very succinctly\nThe Open Policy Agent (OPA) is an open source, general-purpose policy engine. OPA provides a declarative language that letâ€™s you specify policy as code and APIs to offload policy decision-making from your software. OPA to enforce policies in microservices, Kubernetes, CI/CD pipelines, API gateways, or nearly any other software.\nOPA focuses exclusively on making policy decisions and not on policy enforcement. OPA pairs with Envoy for policy enforcement. OPA can run as:\n A standalone service accessible via an API A library that can be compiled into your code  It has an extremely flexible programming model:\nAdditionally, the company behind OPA, Styra, offers control plane products to author policies and manage a fleet of OPA instances.\nOPA decouples policy decision-making from policy enforcement. When your software needs to make policy decisions it queries OPA and supplies structured data (e.g., JSON) as input. OPA accepts arbitrary structured data as input.\nOPA generates policy decisions by evaluating the query input against policies and data. OPA expresses policies in a language called Rego. OPA has exploded in popularity and has become a Cloud Native Computing Foundation incubating project. Typical use cases are deciding:\n Which users can access which resources Which subnets egress traffic is allowed Which clusters a workload can be deployed to Which registries binaries can be downloaded from Which OS capabilities a container can execute with The time of day the system can be accessed  Policy decisions are not limited to simple yes/no or allow/deny answers. Policies can generate any arbitrary structured data as output.\nThis getting started example is based on this OPA tutorial using docker-compose instead of Kubernetes.\nSolution Overview In this getting started example we take the super simple envoy environment we created in getting started episode 1 and add the simplest possible authorization rule using Open Policy Agent.\nDocker Compose This is the same docker compose file as our initial getting started example with a few modifications. At line 15 in our docker-compose file, we added a reference to our Open Policy Agent container. This is a special verison of the Open Policy Agent containers on dockerhub. This version is designed to integrate with Envoy and has an API exposed the complies with Envoy\u0026rsquo;s gRPC specification. There are also some other things to take notice of:\n Debug level logging is set on line 21 The gRPC service for Envoy is configured on line 23 The logs are sent to the console for a log aggregation solution to pickup (or not) on line 24  Envoy Config Changes There are a few things that we need to add to the envoy configuration to enable external authorization:\n We added an external authorization configuration at line 23. failure_mode_allow on line 26 determines whether envoy fails open or closed when the authorization service fails. with_request_body determines if the request body is sent to the authorization service. max_request_bytes determines how large of a request body Envoy will permit. allow_partial_message determines if a partial body is sent or not when a buffer maximum is reached. The grpc_service object on line 30 specifies how to reach the Open Policy Agent endpoint to make an authorization decision.  Rego: OPA\u0026rsquo;s Policy Language There are a lot of other examples of how to write Rego policies on other sites. This walkthrough of Rego is targeted specifically to using it to make Envoy decisions:\n The package statement on the first line determines where the policy is located in OPA. When a policy decision is requested, the package name is used as the prefix used to locate the named decision. The import statement on line 3 navigates the heavily nested data structure that Envoy sends us and gives us a shorter alias to refer to a particular section of the input. On line 5 we have a rule named allow and we set it\u0026rsquo;s default value to and object that Envoy is expecting.  The allowed property determines if the request is permitted to go through or not. The headers property allows us to set headers on either the forwarded request (if approved) or on the rejected request (if denied). OPA does not marshal any REGO data types on your behalf. All header values must be specified as a string. The body property can be used to communicate error message details to the requestor. It has no affect on requests approved for forwarding. OPA does not marshal any REGO data types on your behalf. The body value must be specified as a string. The http_status property can be set on any rejected requests to any value as desired   The next section starting at line 12 specifies the logic for approving the request to move forward  On line 12 the allow rule is set to the value of the response variable that we define in the body of the rule Line 13 is the only condition we have defined for approval of the request. The request method simply needs to be a POST. If true then we set the response to the values on lines 15 and 16.    Input data sent from Envoy Now we dive into the details of the input data structure sent from Envoy.\n Line 3 is an object that describes the IP address and Port that the request is going to Line 10 is the request object itself. The unmarshalled body is present along with:  request headers hostname where the original request was sent a unique request ID assigned by Envoy request method unparsed path protocol request size   Line 34 is a object that describes the IP address and port where the request originated Line 45 is where Envoy has already done some work for us to parse the request body (if it was configured to be forwarded) Line 46 and 47 are the parsed path and query parameters respectively Finally, line 48 let\u0026rsquo;s us know whether we have the complete request body or not  Reviewing the Request Flow in Envoy\u0026rsquo;s Logs In debug mode, we have a lot of rich information that Envoy logs for us to help us determine what may be going wrong as we develop our system.\n Line 1 shows our request first coming in The next several lines show us the request headers Line 13-14 let\u0026rsquo;s us know that envoy is buffering the request until it reaches the buffer limit that we set Line 16-20 show us that Envoy forwarded the request to our authorization service and got an approval to forward the request The remainder of the logs show envoy forwarding the request to its destination and then back to the calling client  Reviewing OPA\u0026rsquo;s Decision Log The open policy agent decision logs include the input that we just reviewed and some other information that we can use for debugging, troubleshoot or audit logging. The interesting parts that we haven\u0026rsquo;t reviewed yet:\n The decision ID on line 2 can be matched against other OPA log entries related to this decision Line 5 - Envoy sends us the destination of the request Line 7 - Envoy sends the request details. The unmarshalled body is only available if we setup the buffering and forwarding in the Envoy configuration. line 30 - Envoy also sends us the source IP address that it received the request from. Line 37 has the labels that show which Envoy instance the request came from Line 42 is an object that contains the performance metrics for the decision Line 50 shows the response that OPA sent back to Envoy  Taking this solution for a spin Now that we know what we are looking at, we can run this example by executing the script ./demonstrate_opa_integration.sh\n The script starts the envoy front proxy, HTTPBIN and Open Policy Agent Next it shows the docker container status to make sure everything is up and running. Curl is used to issue a request that should get approved, forwarded to HTTPBin and the display the results The opa decision logs are then shown to let you explore the information available for development debugging and troubleshooting To make sure we show both outcomes the next request should fail our simple authorization rule check. The decision logs are shown again Finally the example is brought down and cleaned up.  In the next getting started guide we will explore Open Policy Agent\u0026rsquo;s command line interface and unit testing support.\n",
    "ref": "/blog/envoy_opa_3_adding_open_policy_agent/"
  },{
    "title": "Adding Observability Tools",
    "date": "September 1, 2020",
    "description": "Learn how to add ElasticSearch and Kibana to your Envoy front proxy environment",
    "body": "Photo by Alex Eckermann on Unsplash\nGetting Started with Envoy \u0026amp; Open Policy Agent \u0026mdash; 02 \u0026mdash; Adding Log Aggregation to our Envoy Example This is the 2nd Envory \u0026amp; Open Policy Agent (OPA) Getting Started Guide. Each guide is intended to explore a single Envoy or OPA feature and walk through a simple implementation. Each guide builds on the concepts explored in the previous guide with the goal of creating a very powerful authorization service by the end of the series.\nWhile our solution is still very simple, it is a great time to show how to make our solution observable with log aggregation. This makes it easier to think about how to scale and productionize our solution. As we start to develop and apply authorization rules at scale it will be handy to have all of the logs aggregated and displayed in one place for development and troubleshooting activies. In this article we will walk through how to setup the EFK stack to pull your logs together from all of the docker containers in your local development environment.\nAll of the source code for this getting started example is located on github. \u0026mdash;\u0026mdash;\u0026gt; Envoy \u0026amp; OPA GS # 2 \nHere is a list of the Getting Started Guides that are currently available.\nGetting Started Guides  Using Envoy as a Front Proxy Adding Observability Tools Plugging Open Policy Agent into Envoy Using the Open Policy Agent CLI  Solution Overview The solution that we will build in this blog is shown below. We will send docker logs into an EFK stack that is also running inside docker. Each of the containers in our solution simply send logs to Standard out and / or Standard Error. No agents nor other special software is requirements are imposed on the observered applications.\nAdding EFK containers We will be using Fluent Bit in this example because it is lite weight and simpler to deal with than Logstash or full fledged FluentD. Below is a very basic configuration with no special optimizations. Lines 18 - 49 add the EFK stack to our environment. Lines 16 and 47 use the depend_on property to cause docker to start elasticSearch first and then Kiban and Fluent Bit that depend on elasticSearch.\nWiring our containers into EFK With the EFK log aggregation containers added to our docker-compose file, we now need to wire them into the other containers in our environment. The changes below show a couple of small changes that we needed to make to our compose file from where we left off in Getting Started Guide #1. We added the property at line 14 below which expresses our dependency on elasticSeach. Additionally, we need to wire standard out and standard error from our containers to Fluent Bit. This is done through the logging properties on lines 17 and 27. The driver line tells docker which log driver to use and the tag help make it more clear which container is the source of the logs.\nTaking things for a spin The demonstration script spins everything up for us. Just run ./demonstrate_front_proxy.sh to get things going:\n It downloads and spins up all of our containers. Then it waits 30 seconds to give elasticSearch some time to get ready and some time for Kibana to know that elasticSearch is ready. A curl command sends Envoy a request to make sure the end-to-end flow is working. If that worked, proceed forward. If not wait a bit longer to make sure elasticSearch and Kibana are both ready. If you are running on Mac OS X then the next step will open a browser and take you to the page to setup your Kibana index. If it doesn\u0026rsquo;t work, simply open your browser and go to http://localhost:5601/app/kibana#/management/kibana/index_pattern?_g=() you should see something like this:  I simply used log* as my index and clicked next. Which should bring up a screen to select the timestamp field name. Select @timestamp and click create index. You should see some field information about your newly created index.  The script then uses the Open command to navigate to the log search interface. If it doesn\u0026rsquo;t work on your operating system then simply navigate to http://localhost:5601/app/kibana#/discover. You should see something like this with some log results already coming in. If you have an interest, you may want to select the container_name and log columns to make it easier to read through the debug logs and results of your testing efforts.  The script sends another request through envoy and you should be able to see the logs coming into EFK.  The script with then take down the environment.  In the next getting started guide, we will add in Open Policy Agent and begin experimenting with a simple authorization rule.\n",
    "ref": "/blog/envoy_opa_2_adding_observability/"
  },{
    "title": "Using Envoy as a Front Proxy",
    "date": "August 31, 2020",
    "description": "Learn how to set up Envoy as a front proxy with docker",
    "body": "Photo by Mattia Serrani on Unsplash\nGetting Started with Envoy \u0026amp; Open Policy Agent \u0026mdash; 01 \u0026mdash; Using Envoy as a Front Proxy This is the 1st Envory \u0026amp; Open Policy Agent (OPA) Getting Started Guide. Each guide is intended to explore a single Envoy or OPA feature and walk through a simple implementation. Each guide builds on the concepts explored in the previous guide with the end goal of building a very powerful authorization service by the end of the series.\nThe source code for this getting started examples is located on Github. \u0026mdash;\u0026mdash;\u0026gt; Envoy \u0026amp; OPA GS # 1 \nHere is a list of the Getting Started Guides that are currently available.\nGetting Started Guides  Using Envoy as a Front Proxy Adding Observability Tools Plugging Open Policy Agent into Envoy Using the Open Policy Agent CLI  Overview Envoy is an open source edge and service proxy that has become extremely popular as the backbone underneath most of the leading service mesh products (both open source and commercial). This article is intended to demystify it a bit and help people understand how to use it on it\u0026rsquo;s own in a minimalist fashion.\nEnvoy is just like any other proxy. It receives requests and forwards them to services that are located behind it. The 2 ways to deploy Envoy are:\n  Front Proxy - In a front proxy deployment Envoy is very similar to NGINX, HAProxy, or an Apache web server. The Envoy server has it\u0026rsquo;s own IP address and is a separate server on the network from the services that it protects. Traffic comes in and get forwarded to a number of different services that are located behind it. Envoy supports a variety of methods for making routing decisions.\n One mechanism is to use path based routing to determine the service of interest. For instance a request coming in as: /service1/some/other/stuff can use the first uri path element as a routing key. service1 can be used to route requests to service 1. Additionally, service2 in /service2/my/applications/path can be used to route the request to a set of servers that support service 2. The path can be rewritten as it goes through Envoy to trim off the service routing prefix. Another mechanism is to use Server Name Indication (SNI) which is a TLS extension to determine where to forward a request. Using this technique, service1.com/some/other/stuff would use the server name to route to the service1 services. Additionally, service2.com/my/applications/path would use service2.com to route the request to service2. The diagram above shows the front proxy approach.    Sidecar Proxy - In a sidecar deployment, the Envoy server is located at the same IP address as each service that it protects. The Envoy server when deployed as as sidecar only has a single service instance behind it. The sidecar approach can intercept all inbound traffic and optionally all outbound traffic on behalf of the service instance. IP Tables rules are typically used to configure the operating system to capture and redirect this traffic to Envoy. The diagram above shows the sidecar approach.\n  In this article and example project we will start with the simplest possible Envoy deployment. This example just uses docker compose to show how to get Envoy up and running. There will be a number of subsequent articles that expand on this simple approach to demostrate more Envoy capabilies. Open Policy Agent will also be introduced to handle more complex authorization use cases that cannot be handled by Envoy alone.\nThe diagram below shows the environment that we are about to build and deploy locally.\nBuilding an Envoy Front Proxy The code for the complete working example can be found on Github. We will start with the Envoy docker images. The Envoy images are located on Dockerhub. We will use docker-compose to build some configurability into our Envoy environment.\nDockerfile The entrypoint.sh file is where the magic happens. We will configure environment variables in our docker-compose file to determine which service (SERVICE_NAME) Envoy routes to and the port (SERVICE_PORT) on that service. Additionally, we specify how much detail is captured in the logs by setting the DEBUG_LEVEL environment variable. As you can see from the script below on line 3, we replace those environment variables on the fly in Envoy\u0026rsquo;s configuration file before starting Envoy.\nentrypoint.sh Since we don\u0026rsquo;t have a configuration file yet, we will cover that next. Envoy is very flexible and powerful. There is an enormous amount of expressiveness that the Envoy API and configuration files support. With this flexibility and power, Envoy configuration files can become quite complicated with a lot layers in the YAML hierarchy. Additionally, each feature has a lot of configuration parameters. The documentation can only cover so much of that functionality with an open source community of volunteers.\nOne of the challenges that I have when reading through the documentation and trying to apply it, is that the documentation has a variety of YAML snippets. There are very few places that these YAML snippets are pulled together into a functioning example. There are a few examples in the source code examples directory but they are far from comprehensive. That leaves a lot of tinkering for engineers to figure out how to compose a functional configuration while interpretting sometimes unclear error messages on their way to the promised land. That is the entire reason that I am writting a series of getting started guides. These articles are intended to give folks a known to work starting point for Envoy authorization features and extensions like Open Policy Agent.\nThe Envoy configuration starts with defining a listener as we can see starting on line 3. The first property is the address and port to accept traffic on (lines 3 through 6). The next property is a filter chain. Filter chains are very powerful and enable configuration for a wide variety of possible behaviors. This filter chain is as simple as it gets. It simply accepts any HTTP traffic with any URI pattern and routes it to the cluster named service.\nThe http_connection_manager component does this for us. It\u0026rsquo;s configuration starts on line 9 and extends to line 24. Execution order is determined by the order they are listed in the configuration file. The important part for this discussion begins on line 14 with the route_config. This sets up routing requests for any domain (line 18) and any request URI that begins with a slash (line 20) to go to the cluster named service. The cluster definitions are in a separate section to make them reusable destination across a variety of rules.\nEnvoy Configuration (envoy.yaml) The cluster definitions begin on line 25. We can see that there is only a single cluster defined. It has the name service, uses DNS to find server instances and uses round robin to direct traffic across multiple instances. The hostname is on line 32 and the port is on line 33. As we can see these are the environment variables that we will swap out with the entry.sh script.\nThe last section of the configuration file tells Envoy where to listen for admin traffic. The admin gui is a handy little tool that we will not cover in this guide but is definitely worth poking around in to observe what is going on inside an individual Envoy instance.\nDocker Compose Configuration Now that we understand the Envoy configuration we can move on to understanding the rest of the simple environment that we are setting up. Line 4 shows the trigger that causes docker to build the Envoy container. Docker will only build the Envoy Dockerfile the first time it sees that an image does not exist. If you want to force rebuilding the Envoy container on subsequent runs add the --build parameter to your docker compose command. We expose Envoy to the host network on lines 6 and 7 and provide the configuration file that we just created on line 9.\nThe service to route to and port are defined on the environment variables on lines 12 and 13. Notice the name app matches the name of our final service on line 15. We are simply using HTTPBIN to reflect our request back to us.\nRunning and Trying out our Example The last step to getting our front proxy up is simply running the included script test.sh that demonstrates our example. The script explains what it is about to do to ensure you know what are about to see scrolling across your terminal screen. Line 3 starts our environment. Line 8 let\u0026rsquo;s you check to make sure both containers are running before trying to send them a request.\nLine 10 simply calls Envoy with a curl command with the --verbose parameter set so that you can see the headers and request details. Then line 12 tears down the whole environment.\nContainers UP!!!! If you have successfully started your environment then you should see something like this:\nWe Succeeded!!! You should see something like this if you successfully called HTTPBin through Envoy:\nCongratulations Congratulations, you have successully stood up your first Envoy instance and configured it to forward traffic! This is the simplest possible Envoy configuration :) We don\u0026rsquo;t have any security yet or any other features that Envoy is famous for. We will get to that in future articles. Feel free to use postman to explore other request that you can send. Additionally, don\u0026rsquo;t forget to explore Envoy\u0026rsquo;s admin console by pointing your web browser to http://localhost:8001\n",
    "ref": "/blog/envoy_opa_1_front_proxy/"
  },{
    "title": "About",
    "date": "February 28, 2019",
    "description": "Helpful Badger, searching the world for helpful tech tips",
    "body": "Photo by Vincent van Zalinge on Unsplash\nThe Helpful Badger loves technology. He travels the world looking for interesting technology topics and shares his perspective on what he finds.\nIf you see him out it the woods seeking his next adventure, offer him a StarBucks Pike Place coffee. He\u0026rsquo;ll gladly pull up a chair and talk tech with you!\n",
    "ref": "/about/"
  }]
